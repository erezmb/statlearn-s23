\documentclass{article}

\def\ParSkip{} 
\input{../../common/ryantibs}

\title{Homework 4 \\ \smallskip
\large Advanced Topics in Statistical Learning, Spring 2023 \\ \smallskip
Due Friday April 14 at 5pm}
\date{}

\begin{document}
\maketitle
\RaggedRight
\vspace{-50pt}

\section{Basic fact about CDFs and quantiles [15 points]}

In this exercise, we'll walk through a number of basic but important facts about 
quantiles and cumulative distribution functions (CDFs). Let $F$ be a CDF, of the
form 
\[
F(x) = \P(X \leq x), \quad x \in \R,
\]
for some real-valued random variable $X$. Let $Q$ be the corresponding quantile 
function,
\[
Q(t) = \inf \{ x : F(x) \geq t \}, \quad t \in [0,1].
\]
(This is often denoted as $Q = F^{-1}$, even when the inverse of $F$ does not
exist in the usual sense.) We note that $F$ is always nondecreasing and 
right-continuous; the latter says, for any $x$,    
\[
F(x) = \lim_{y \to x^+} F(y)
\]
(where $y \to x^+$ means that $y$ approaches $x$ from the right).
% Similarly, $Q$ is always nonincreasing and left-continuous; the latter says, 
% for any $t$,  
% \[
% Q(t) = \lim_{u \to t^-} Q(u)
% \]
% (where $u \to t^-$ means that $u$ approaches $t$ from the left).

\begin{enumerate}[label=(\alph*)]
\item Prove that for any $x$ and any $t$, 
  \marginpar{\small [3 pts]}
  \[
  F(x) \geq t \iff Q(t) \leq x.
  \]
  This is sometimes called the \emph{Galois inequality} for the quantile
  function. Hint: one direction follows from the definition of $Q$, and the
  other is a consequence of right-continuity of $F$.  

\item Use part (a) to prove that if $U \sim \mathrm{Unif}(0,1)$, then $Q(U)$ is
  distributed according to $F$ (which means it has CDF $F$).
  \marginpar{\small [2 pts]}

\item Use part (a) to prove that for any $t$, 
  \marginpar{\small [2 pts]}
  \[
  F(Q(t)) \geq t,
  \]
  with strict inequality if and only if $t$ is not in the range of $F$. 

\item Use parts (b) and (c) to prove that if $X$ is distributed according to
  $F$, then $F(X)$ is sub-uniform, which means that for any $t$, 
  \marginpar{\small [3 pts]}
  \[
  \P(F(X) \leq t) \leq t.
  \]
  with equality $\P(F(X) \leq t) = t$ if and only if $t$ is in the closure of
  the range of $F$. Hint: you may start by replacing $X$ with $Q(U)$, for $U
  \sim \mathrm{Unif}(0,1)$, as they have the same distribution.  
  
\item Give a concrete worked example to show when equality fails in the result  
  in part (d).
  \marginpar{\small [1 pt]}

\item We can always achieve equality in part (d) via auxiliary randomization.
  Define
  \[
  F^*(x; v) =  \lim_{y \to x^-} F(y) + v \cdot \Big( F(x) - \lim_{y \to x^-},
  F(y) \Big),
  \]
  where $y \to x^-$ means that $y$ approaches $x$ from the left. Show
  empirically, by revisiting your example in part (e), that for $V \sim
  \mathrm{Unif}(0,1)$, independent of $X$, and for any $t$,      
  \marginpar{\small [1 pt]}
  \[
  \P(F^*(X; V) \leq t) = t.
  \]
  Bonus: prove it!
\end{enumerate}

\section{Calibration-conditional beta coverage [18 points]}

\def\hC{\hat{C}}

Let $D_1$ and $D_2$ be an arbitrary partition of $\{1,\dots,n\}$ into sets of
sizes $n_1=|D_1|$ and $n_2=|D_2|$. Recall, in lecture, we stated that for the
split conformal prediction band \smash{$\hC_n$}, computed on a proper training
points $(X_i,Y_i)$, $i \in D_1$ and a calibration points $(X_i,Y_i)$, $i \in
D_2$, it holds that  
\begin{equation}
\label{eq:coverage_beta_split}
\P\Big(Y_{n+1} \in \hC_n(X_{n+1}) \, \Big| \, (X_i,Y_i), \, i=1,\dots,n \Big) 
\sim \mathrm{Beta}(k_\alpha, n_2+1-k_\alpha), 
\end{equation}
where $k_\alpha = \lceil (1-\alpha)(n_2+1) \rceil$. This assumes that
$(X_i,Y_i)$, $i=1,\dots,n+1$ were all i.i.d.\ draws from some arbitrary
distribution $P$. In what follows, you will work towards a proof of the result
in \eqref{eq:coverage_beta_split}.   

\begin{enumerate}[label=(\alph*)]
\item Let $U_1,\dots,U_n$ be i.i.d.\ from $\mathrm{Unif}(0,1)$, and denote their
  \emph{order statistics} by  
  \[
  U_{(1)} \leq U_{(2)} \leq \cdots \leq U_{(n)}.
  \]
  Fix any $1 \leq k \leq n$. Prove that the density $f_{(k)}$ of $U_{(k)}$ is
  given by 
  \marginpar{\small [4 pts]}
  \[
  f_{(k)}(x) = n {n-1 \choose k-1} x^{k-1} (1-x)^{n-k}.
  \]
  Hint: calculate the probability that $U_{(k)}$ lies in $[x,x+\epsilon]$, then
  send $\epsilon \to 0$.
  
\item From the result in part (a), argue that 
  \marginpar{\small [1 pt]}
  \[
  U_{(k)} \sim \mathrm{Beta}(k, n+1-k).
  \]
  (You just need to recall the form of the beta distribution; you don't need to
  do any hard calculations here.)

\item Now let $X_1,\dots,X_{n+1}$ be i.i.d.\ according to $F$, and assume that
  $F$ is continuous. Prove that 
  \marginpar{\small [3 pts]}
  \[
  \P\big( X_{n+1} \leq X_{(k)} \,|\, X_1,\dots,X_n \big) \sim \mathrm{Beta}(k,
  n+1-k). 
  \]
  Hint: let $U_i = F(X_i)$, $i=1,\dots,n+1$. Use Q1 part (d) to argue that each
  $U_i \sim \mathrm{Unif}(0,1)$. Then use the result from part (b) of this
  question.  

\item Use part (c) to show that the split conformal prediction result
  \eqref{eq:coverage_beta_split} holds whenever the distribution of each
  conformity score $V(X_i,Y_i)$ is continuous.  
  \marginpar{\small [2 pts]}

\item Show that the result in part (c) still holds when the CDF $F$ is not 
  necessarily continuous, and therefore the result in
  \eqref{eq:coverage_beta_split} holds in general, even when each $V(X_i,Y_i)$
  does not have a continuous distribution (and ties can occur with positive
  probability).  
  \marginpar{\small [3 pts]}

  Hint: using Q1 part (b), argue that you we replace each $X_i$ with $Q(U_i)$,
  where $Q$ denotes the quantile function associated with $F$, and $U_i$, 
  $i=1,\dots,n$ are i.i.d.\ from $\mathrm{Unif}(0,1)$. Then use the fact that
  $Q$ is itself nondecreasing.

\item Carry out a simulation to empirically verify
  \eqref{eq:coverage_beta_split} for split conformal prediction. You may fix
  $\alpha$, but examine a few different values of the calibration set size
  $n_2$.   
  \marginpar{\small [5 pts]}
\end{enumerate}

\section{X-conditional coverage: impossible! [18 points]}

In lecture, we briefly discussed an impossibility result for X-conditional
coverage in a distribution-free setting. This exercise investigates
X-conditional coverage more deeply from theoretical and practical angles. 

\begin{enumerate}[label=(\alph*)]
\item Recite and prove any of the impossibility results in
  \citet{lei2014distribution, vovk2012conditional, barber2021limits}. Note: it's
  perfectly fine for your solution to follow directly from what's in any of
  those papers---no new arguments are needed---but make sure to be fully precise
  in stating the result and providing its proof, all in your own words.  
  \marginpar{\small [8 pts]}

\item Conduct a simulation to show that, nonetheless, different conformity
  scores can give rise to appreciably different results in terms of approximate
  conditional coverage in practice. By ``approximate'' here, we mean some
  kind of local coverage, where we average over a small neighborhood of a point 
  $x$.    

  Start with the absolute residual as your conformity score, and then compare
  its approximate conditional coverage performance to at least one other
  conformity score (a number of choices are available), where you have designed
  the latter to do better in your simulation. Note: split conformal is fine to
  use throughout.  
  \marginpar{\small [10 pts]}
\end{enumerate}



\bibliographystyle{plainnat}
\bibliography{../../common/ryantibs}

\end{document}